# MMM-Faces
This an extension for the [MagicMirror](https://github.com/MichMich/MagicMirror) and a fork of [MMM-Facial-Recognition](https://github.com/paviro/MMM-Facial-Recognition). Similar to the original work it provides module swapping according to the detected user.

Several things were added:

- More face detection algorithms:
    - Dlib's Frontal Face Detector: Pretty good accuracy and very fast on CPU (default)
    - OpenCv's DNN face detector: Highest accuracy (probably) and reasonable fast (even on CPU)
    - Dlib's CNN based Face detector: High accuracy (Use on Cuda enabled devices like Nvidia Jetson)
- More face recognition algorithms:
    - Most notable Dlib's face descriptor: Should work with only one example Image per user.
- Option to check for messages from [MMM-PIR-Sensor](https://github.com/paviro/MMM-PIR-Sensor): Stop searching for faces if there is nobody around.
- Incorporates the [Motion Detection module](https://github.com/dmcinnes/MMM-Motion-Detection), which is also a fork of [MMM-Facial-Recognition](https://github.com/paviro/MMM-Facial-Recognition).

## Installation


## Dependencies
- [python-shell](https://www.npmjs.com/package/python-shell) (installed via `npm install`)
- [OpenCV](http://www.opencv.org) (`sudo apt-get install libopencv-dev python-opencv`)
- [Dlib](http://www.dlib.net/)



## Usage
Before you can use this module, you have to provide example images for the users you want to recognize. For each user create a folder with one or more images of that person:

```
mkdir models/trainingImages/<USERNAME>

```

The file name of the images doesn't matter. 
After that run the training script and follow the instructions:

```
python pythonFunctions/updateFaceDescriptors.py

```
At the beginning you have the option to take additional images with your webcam. 
In general one image per person should be enough. If more than one image is provided, the script also trains a classifier (either a SVM classifier or simple KNN)

After the initial setup is down, copy the MMM-Faces folder into your modules location and add the following entry to your config.js.
Note that you only have to copy the variables, for which you want to change the default value. For documentation purposes all possible entries are listed here with default values and some comments. You probably don't want to change a lot, except you want to play around with the different algorithms.

```
{
	module: 'MMM-Faces',
	config: {
        //////////////////////////
		// GENERAL VARIABLES    //
		//////////////////////////
		// force the use of a usb webcam on raspberry pi (on other platforms this is always true automatically)
		useUSBCam: false,
		// recognition intervall in seconds (smaller number = faster but CPU intens!)
		interval: 2,
		// Logout delay after last recognition so that a user does not get instantly logged out if he turns away from the mirror for a few seconds
		logoutDelay: 15,
		// Array with usernames (copy and paste from training script)
		//TODO: Check if this is needed 
		//users: [],
		//Module set used for strangers and if no user is detected
		defaultClass: "default",
		//Set of modules which should be shown for every user
		everyoneClass: "everyone",
		// Boolean to toggle welcomeMessage
		welcomeMessage: true,
		
		//////////////////////////
		// ALGORITHM VARIABLES  //
		//////////////////////////
        
        // Detection Algorithm:
        DETECTION_ALGORITHM: "dlib_hog", // "dlib_hog" | "ocv_dnn" | "dlib_cnn" | "haar"
		// Recognition Algorithm:
		RECOGNITION_ALGORITHM: "dlib_face_encoding", // "dlib_face_encoding" | "legacy"
		// location of the images used by the updateFaceDescriptors.py script
		IMAGE_DIR: 'modules/MMM-Faces/models/trainingImages',
		//Tolerance for distance between face_encodings
		DLIB_RECOGNITION_TOLERANCE: 0.6,
		DLIB_RECOGNITION_MODEL_LOCATION: 'modules/MMM-Faces/models/dlib_recogntion.tflite',
		// location of the face encodings file generated by the updateFaceDescriptors.py script
		FACE_DESCRIPTOR_LOCATION: 'modules/MMM-Faces/models/face_encodings.pkl',
		// Classifier: If a lot of images are provided, an additional classifier is used
		CLASSIFIER_LOCATION: "svm", // "svm" | "knn"
		
		//////////////////////////
		// LEGACY VARIABLES     //
		//////////////////////////
		
		// These variables are only used for the old algorithms. You probably don't need them.
		// 1=LBPH | 2=Fisher | 3=Eigen
		CLASSIC_RECOGNITION_ALGORITHM: 1,
		// Path to your training xml for the old algorithms. This is the file, generated from Paviro's training tool
		CLASSIC_TRAINING_FILE: 'modules/MMM-Facial-Recognition/training.xml',
		// Threshold for the confidence of a recognized face before it's considered a
		// positive match.  Confidence values below this threshold will be considered
		// a positive match because the lower the confidence value, or distance, the
		// more confident the algorithm is that the face was correctly detected.
		lbphThreshold: 50,
		fisherThreshold: 250,
		eigenThreshold: 3000
		
	}
}
```

For this module to take effect you have to assign classes to your modules. The defaultClass (`default`) is shown if no user or a stranger is detected. The everyoneClass (`everyone`) is shown for all users. To specify modules for a certain user, use their name as classname.

```
{
	module: 'example_module',
	position: 'top_left',
	//Set your classes here seperated by a space.
	//Shown for all users
	classes: 'default everyone'
},
{
	module: 'example_module2',
	position: 'top_left',
	//Only show for specific user
	classes: 'MaxMustermann'
}
```
## Optimizations
Since these algorithms can be quite demanding, especially for small devices like a Raspberry Pi, a few things should be considered.

1. Choose the right algorithm for your device: If you use a Rpi or similar device the default HoG detector should be fine. Consider either Opencv's DNN detector if you're not satisfied with the detection accuracy and your CPU is fast enough (The difference to HoG is not huge, approx. 30%). Use dlib_cnn only if you have a Cuda enabled device (Probably the best choice on a Nvidia Jetson).
2. Use a recent version of OpenCV and compile it yourself: Especially ARM devices benefit a lot from vectorized code (NEON instructions). In the future I will provide precompiled libraries, at least for the Rpi 



